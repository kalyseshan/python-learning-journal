{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oklgMeycSF4D"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import csv\n",
        "import time\n",
        "\n",
        "'''\n",
        "Generating CSV file:\n",
        "- Create possible products, sale dates, and prices\n",
        "- Write into CSV file given the dataset size as input\n",
        "'''\n",
        "\n",
        "# Create class to generate datasets\n",
        "class Sale:\n",
        "  def __init__(self, datasize):\n",
        "    self.datasize = datasize\n",
        "\n",
        "  def createDate(self): # Possible sale dates\n",
        "    year = random.randint(2000, 2025)\n",
        "    month = random.randint(1, 12)\n",
        "    if month == 2:\n",
        "      day = random.randint(1, 28)\n",
        "    elif month % 2 == 0:\n",
        "      day = random.randint(1, 30)\n",
        "    else:\n",
        "      day = random.randint(1, 31)\n",
        "    if day < 10:\n",
        "      day = (f\"{0}{day}\")\n",
        "    if month < 10:\n",
        "      month = (f\"{0}{month}\")\n",
        "    return (f\"{year}-{month}-{day}\")\n",
        "\n",
        "  def createPrice(self): # Possible sale amounts\n",
        "    integer = random.randrange(50, 305, 5)\n",
        "    decimals = [random.randrange(0, 95, 5), 99]\n",
        "    decimal = random.choice(decimals)\n",
        "    if decimal < 10:\n",
        "      decimal = (f\"{0}{decimal}\")\n",
        "    return  (f\"{integer}.{decimal}\")\n",
        "\n",
        "  def productName(self):\n",
        "    product_names = ['Widget', 'Gadget', 'Thingamajig', 'Doohickey'] # Products being sold\n",
        "    product = random.choice(product_names)\n",
        "    return product\n",
        "\n",
        "  def compiledSales(self, datasize):\n",
        "    all_sales = []\n",
        "    for num in range(self.datasize):\n",
        "      date = self.createDate()\n",
        "      amount = self.createPrice()\n",
        "      name = self.productName()\n",
        "      sale_information = [date, amount, name]\n",
        "      all_sales.append(sale_information)\n",
        "    all_sales.sort(reverse = True) # Sort list in descending order (most recent sale first)\n",
        "    for sale in range(len(all_sales)):\n",
        "      all_sales[sale].insert(0, sale) # Add sale ID to the first position (0) in each sale\n",
        "    return all_sales\n",
        "\n",
        "  def createCSV(self, datasize): # Create CSV file\n",
        "    with open('salesrecords.csv', 'w', newline = '') as csvfile:\n",
        "      content = self.compiledSales(datasize)\n",
        "      writer = csv.writer(csvfile)\n",
        "      for row in range(len(content)):\n",
        "        sale = content[row]\n",
        "        writer.writerow(sale)\n",
        "\n",
        "  def readCSV(self, datasize): # Check content of generated CSV (I used this as a test, not part of the homework)\n",
        "    salesrecords_csv = self.createCSV(datasize)\n",
        "    with open('salesrecords.csv', newline = '') as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      for row in reader:\n",
        "        print(', '.join(row))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Program to process sales records:\n",
        "- Includes options for:\n",
        "  - Load in sales data (read from CSV):\n",
        "    - Big O time complexity (theoretical) = O(n^n)\n",
        "  - Retrieve the latest sale:\n",
        "    - Big O time complexity (theoretical) = O(1)\n",
        "  - Compute total revenue:\n",
        "    - Big O time complexity (theoretical) = O(n)\n",
        "  - Check for duplicate sale IDs\n",
        "    - Big O time complexity (theoretical) = O(n^2)\n",
        "  - Search for a sale by its ID\n",
        "    - Big O time complexity (theoretical) = O(n^2)\n",
        "'''\n",
        "\n",
        "class SaleProcessing:\n",
        "  def __init__(self, datasize):\n",
        "    self.datasize = datasize\n",
        "\n",
        "# Load in sale data from CSV\n",
        "  def load(self):\n",
        "    start = time.time() # Start timer\n",
        "\n",
        "    with open('salesrecords.csv', newline = '') as csvfile: # O(1) --> file size does not matter\n",
        "      reader = csv.reader(csvfile) # O(1)\n",
        "      for row in reader: # O(n)\n",
        "        print(', '.join(row)) # O(n)\n",
        "\n",
        "    stop = time.time() # Stop timer\n",
        "    duration = stop - start\n",
        "    print(\"Time elapsed: \", duration)\n",
        "\n",
        "# Retrieve the latest sale\n",
        "  def last(self):\n",
        "    start = time.time() # Start timer\n",
        "\n",
        "    with open('salesrecords.csv') as csvfile: # O(1)\n",
        "      last_sale = csvfile.readline() # O(1)\n",
        "      print(last_sale) # O(1)\n",
        "\n",
        "    stop = time.time() # Stop timer\n",
        "    duration = stop - start\n",
        "    print(\"Time elapsed: \", duration)\n",
        "\n",
        "# Compute total revenue\n",
        "  def revenue(self):\n",
        "    start = time.time() # Start timer\n",
        "\n",
        "    with open('salesrecords.csv') as csvfile: # O(1)\n",
        "      reader = csv.reader(csvfile) # O(1)\n",
        "      total = 0 # O(1)\n",
        "      for row in reader: # O(n)\n",
        "        total += float(row[2]) # O(1)\n",
        "      print(total)\n",
        "\n",
        "    stop = time.time() # Stop timer\n",
        "    duration = stop - start\n",
        "    print(\"Time elapsed: \", duration)\n",
        "\n",
        "# Check for duplicate sale IDs\n",
        "  def duplicate(self):\n",
        "    start = time.time() # Start timer\n",
        "\n",
        "    with open('salesrecords.csv') as csvfile: # O(1)\n",
        "      reader = csv.reader(csvfile) # O(1)\n",
        "      sale_IDs = [] # O(1)\n",
        "      for row in reader: # O(n)\n",
        "        sale_IDs.append(row[0])\n",
        "      if len(set(sale_IDs)) != len(sale_IDs): # O(1)\n",
        "        result = \"Duplicate sale IDs present.\"\n",
        "      else:\n",
        "        result = \"Duplicate sale IDs not found.\"\n",
        "      print(result)\n",
        "\n",
        "    stop = time.time() # Stop timer\n",
        "    duration = stop - start\n",
        "    print(\"Time elapsed: \", duration)\n",
        "\n",
        "# Search for a sale by its ID\n",
        "  def search(self, datasize):\n",
        "\n",
        "    while True: # Error handling for sale ID search\n",
        "      sale_ID = eval(input(\"Enter a sale ID to search for a sale: \"))\n",
        "      if sale_ID >= datasize:\n",
        "        print(\"Please enter a value within the sale ID bounds.\")\n",
        "        continue\n",
        "      elif sale_ID <= 0:\n",
        "        print(\"Please enter a non-negative and non-zero sale ID.\")\n",
        "        continue\n",
        "      elif int(sale_ID) != sale_ID:\n",
        "        print(\"Please enter an integer value.\")\n",
        "        continue\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    start = time.time() # Start timer\n",
        "\n",
        "    with open('salesrecords.csv') as csvfile: # O(1)\n",
        "      reader = csv.reader(csvfile) # O(1)\n",
        "      for row in reader: # O(n)\n",
        "        if str(sale_ID) in row[0]: # O(n)\n",
        "          print(', '.join(row)) # O(1)\n",
        "\n",
        "    stop = time.time() # Stop timer\n",
        "    duration = stop - start\n",
        "    print(\"Time elapsed: \", duration)\n"
      ],
      "metadata": {
        "id": "7GbH3yrfSJb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User input for dataset size\n",
        "while True: # Error handling\n",
        "  dataset_size = eval(input(\"Enter dataset size: \"))\n",
        "  if dataset_size <= 0:\n",
        "    print(\"Please enter a non-negative and non-zero number.\")\n",
        "    continue\n",
        "  elif int(dataset_size) != dataset_size:\n",
        "    print(\"Please enter an integer value.\")\n",
        "    continue\n",
        "  else:\n",
        "    break\n",
        "\n",
        "# Create dataset\n",
        "setup_1 = Sale(dataset_size)\n",
        "setup_1.createCSV(dataset_size)\n",
        "n = SaleProcessing(dataset_size)\n",
        "\n",
        "# User interaction with program\n",
        "options = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "while True:\n",
        "  response = eval(input(\"Choose an operation (number): 0. Exit Program 1. Load data, 2. Last Sale, 3. Total Revenue, 4. Check Duplicates, 5. Search by Sale ID\"))\n",
        "  if response not in options:\n",
        "    print(\"Please enter a valid option.\")\n",
        "  elif response == 1:\n",
        "    n.load()\n",
        "  elif response == 2:\n",
        "    n.last()\n",
        "  elif response == 3:\n",
        "    n.revenue()\n",
        "  elif response == 4:\n",
        "    n.duplicate()\n",
        "  elif response == 5:\n",
        "    n.search(dataset_size)\n",
        "  else:\n",
        "    print(\"Exited Program\")\n",
        "    break"
      ],
      "metadata": {
        "id": "pplSPkPnvWCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "- https://docs.python.org/3/library/csv.html\n",
        "\n",
        "# Graphs\n",
        "https://docs.google.com/spreadsheets/d/1rE2t9H8Z6v8zWVc2nteCj0TGukz7iMJQs5QNr6UWRg0/edit?gid=0#gid=0"
      ],
      "metadata": {
        "id": "s77y2Gtb6TDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Trends:\n",
        "\n",
        "1.\n",
        "- How does each operationâ€™s execution time change as the dataset grows?\n",
        "  \n",
        "Searching for a sale using the sale ID and loading the data had linear increases in time elapsed relative to the dataset size. Total revenue and checking for duplicates had seemingly linear increases as well, but the time elapsed increases at a faster rate after a dataset size of 10,000. The latest sale showed a logarithmic O(logn) time complexity.\n",
        "\n",
        "- Do the results align with the theoretical Big O expectations?\n",
        "\n",
        "The results only aligned with the theoretical Big O expectations I found for the revenue, but none of the other expectations. This might be an error on my part in determining the theoretical values for each operation.\n",
        "\n",
        "2.\n",
        "- Real-World Implications: Which steps might become bottlenecks in a production system processing millions of records?\n",
        "\n",
        "The Search operation would be ideal with larger datasets, since the time elapsed plateaus and slightly decreases as the dataset size increases. However, the other four operations would be more of an issue, since their efficiencies worsen linearly.\n",
        "\n",
        "- How would you optimize or replace the inefficient (quadratic) approach?\n",
        "\n",
        "I would avoid nested loops, use break to prevent loops from continuing unnecessarily, and adding cases that could help exit loops early without running the full number of iterations.\n",
        "\n",
        "3.\n",
        "\n",
        "- Practical Adjustments: How might you put together a testing plan for this project?\n",
        "\n",
        "I would adjust my CSV file generation program to have potential errors so that I could see where the processing program fails. Currently, there are no errors (as far as I know of) in the program, so I haven't tested every potential issue. For example, I could add multiple duplicates to the database so that the operation for checking duplicates can be adjusted if necessary.\n",
        "\n",
        "- What additional error handling or data validation would be necessary?\n",
        "\n",
        "From the previous question, I think a large issue in this current program is the duplicate checking operation, which has no way to check for multiple duplicates. Also, identifying the duplicates would be a useful practical adjustment.\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ037Pos-oob"
      }
    }
  ]
}
